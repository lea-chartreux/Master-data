{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5eddd39c-d1d1-43b8-a7e9-61ba296ef4a8",
   "metadata": {},
   "source": [
    "<p>CHARTREUX Léa</p>\n",
    "<h1>Création et paramétrages de réseaux de neurones : perceptron multicouche, réseau convolutif</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50747e48-9308-486c-9336-2ce67beba54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Sequential\n",
    "model = Sequential()\n",
    "import tensorflow.keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import SGD\n",
    "import os\n",
    "os.environ[\"TF_USE_LEGACY_KERAS\"] = \"True\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee818542-b9c4-4616-b763-918efbd1a71f",
   "metadata": {},
   "source": [
    "<H2>1) Perceptron multicouche</H2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83aa459-4216-4278-bbf0-cb37bea8a75c",
   "metadata": {},
   "source": [
    "<h4>Interprétation des résultats des modèles</h4><br><p>Trois modèles de réseau perceptron multicouche ont été construit.<br> Chacun est le résultat de l'ajustement d'un paramètre défini, notamment le nombre de classe considéré par l'activation et en entrée.  <br> Le premier modèle est destiné au choix du nombre d'epoch afin de définir la longueur du processus. L'accuracy était de 23,39%. Ce qui signifie que le modèle prédit justement uniquement 23% des prédictions. <br> Sur le second modèle, le nombre de classes en entrées et sortie du modèle sont passées de 10 à 100. L'accuracy était alors à 97.31 %. Ce modèle a une très bonne justesse de prédiction. Ce sera sur ce modèle que sera réalisé la matrice de confusion. <br> Un dernier modèle a été testé en ajoutant une seconde fonction d'activation softmax dont les classes de sortie sont 100. Ce paramétrage a causé une baisse drastique de l'accuracy qui était de 21,62 %"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95ce6e1-8372-4878-8a44-9cadbdecaf49",
   "metadata": {},
   "source": [
    "<h3> 1.1 Modèle 1</h3><br> <p>batch : 300, nb_epoch : 200, 10 classes en entrée, 10 en sortie, activation sigmoid et softmax </p> <br> loss: 23.39% - accuracy: 93.10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8314b24c-6749-4a44-a9d2-e30e07aa5a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Activation\n",
    "\n",
    "batch_size = 300\n",
    "nb_epoch = 200\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# One-hot encoding - 10 nombre total de classe\n",
    "Y_train = keras.utils.to_categorical(y_train, 10)\n",
    "Y_test = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "#  Reshape each 28x28 image -> 784 dim. vector\n",
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# Normalization - divise par 255 pour obtenir des nombres entre 0 et 1\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "\n",
    "\n",
    "#model1 = Sequential()\n",
    "\n",
    "#model1.add(Dense(100, input_dim=784, name='fc1'))\n",
    "#model1.add(Activation('sigmoid'))\n",
    "\n",
    "#model1.add(Dense(10,  input_dim=100, name='fc2'))\n",
    "#model1.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "model1 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=X_train.shape[1:]),\n",
    "    #or tf.keras.layers.Flatten(input_shape= X_train.shape(28,28,)),\n",
    "    tf.keras.layers.Dense(10, activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00397494-2a68-4366-a8f4-858ac851c084",
   "metadata": {},
   "source": [
    "<h3> 1.2 Modèle 2</h3><br> <br> batch : 300, nb_epoch : 200, 100 classes en entrée, 100 en sortie, activation sigmoid et softmax </p> <br> loss: 8.72% - accuracy: 97.31%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83023b4f-d88b-4d2e-987b-079450968e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Activation\n",
    "\n",
    "batch_size = 300\n",
    "nb_epoch = 200\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# One-hot encoding - 10 nombre total de classe\n",
    "Y_train = keras.utils.to_categorical(y_train, 100)\n",
    "Y_test = keras.utils.to_categorical(y_test, 100)\n",
    "\n",
    "#  Reshape each 28x28 image -> 784 dim. vector\n",
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# Normalization - divise par 255 pour obtenir des nombres entre 0 et 1\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "#model1 = Sequential()\n",
    "\n",
    "#model1.add(Dense(10, input_dim=500, name='fc1'))\n",
    "#model1.add(Activation('sigmoid'))\n",
    "\n",
    "#model1.add(Dense(10,  input_dim=100, name='fc2'))\n",
    "#model1.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "model1 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=X_train.shape[1:]),\n",
    "    #or tf.keras.layers.Flatten(input_shape= X_train.shape(28,28,)),\n",
    "    tf.keras.layers.Dense(100, activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(100, activation='softmax')\n",
    "]) \n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ec51db-cd15-4e60-a925-f299301b4060",
   "metadata": {},
   "source": [
    "<h3> 1.3 Modèle 3</h3><br> <p>batch : 300, nb_epoch : 200, 100 classes en entrée, 100 en sortie, activation sigmoid et 2 softmax </p> <br> loss: 223.91% - accuracy: 21.62%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a9a331-c693-4dfa-8641-32917f833717",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Activation\n",
    "\n",
    "batch_size = 300\n",
    "nb_epoch = 200\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# One-hot encoding - 10 nombre total de classe\n",
    "Y_train = keras.utils.to_categorical(y_train, 100)\n",
    "Y_test = keras.utils.to_categorical(y_test, 100)\n",
    "\n",
    "#  Reshape each 28x28 image -> 784 dim. vector\n",
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# Normalization - divise par 255 pour obtenir des nombres entre 0 et 1\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "#model1 = Sequential()\n",
    "\n",
    "#model1.add(Dense(10, input_dim=500, name='fc1'))\n",
    "#model1.add(Activation('sigmoid'))\n",
    "\n",
    "#model1.add(Dense(10,  input_dim=100, name='fc2'))\n",
    "#model1.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "model1 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=X_train.shape[1:]),\n",
    "    #or tf.keras.layers.Flatten(input_shape= X_train.shape(28,28,)),\n",
    "    tf.keras.layers.Dense(100, activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(100, activation='softmax'),\n",
    "    tf.keras.layers.Dense(100, activation='softmax')\n",
    "]) \n",
    "\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a2081b-6b92-40ce-97e5-075dc790ea6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model1.compile(loss='categorical_crossentropy', \n",
    "               optimizer='sgd', \n",
    "               metrics=['accuracy'])\n",
    "# Then set the learning rate separately if needed\n",
    "model1.optimizer.learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b3f823-7132-4dbb-8195-a0d6d14d747f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model1.fit(X_train, Y_train,batch_size=batch_size, epochs=nb_epoch,verbose=1)\n",
    "scores = model1.evaluate(X_test, Y_test, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model1.metrics_names[0], scores[0]*100))\n",
    "print(\"%s: %.2f%%\" % (model1.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f0ce20-d7ac-47d1-ac81-2a7a3e55578b",
   "metadata": {},
   "source": [
    "<h2>2) Réseau convolutif</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f493a4e0-fe9c-4f34-a5c0-c6a362e62e1d",
   "metadata": {},
   "source": [
    "<h3>Interprétation des résultats des modèles</h3><br><p>Deux modèles de réseau convolutif ont été construit.<br> Chacun est le résultat de l'ajustement d'un paramètre défini par modèle du nombre de classe considéré par l'activation ReLU en entrée.  <br> Le premier est destiné au test du code donnée en classe afin d'interpréter les premiers résultats et ajuster le modèle en conséquence. L'accuracy était de 11%. Ce qui signifie que le modèle classifie justement uniquement 11% des prédictions. <br> Sur le second modèle, le nombre d'epoch est passé à 15 et le nombre d'élément en sortie à 128. L'accuracy était alors à 98%. Ce modèle à une très bonne justesse de prédiction. Ce sera sur ce modèle que sera réalisé la matrice de confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982a14f0-5bc5-4a3e-b87d-886c799223f7",
   "metadata": {},
   "source": [
    "<h3>Introduction des modèles</h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99b37838-4b75-4585-b512-65fb172b7127",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "input_shape = (28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd26642f-4466-450f-9a2a-90be4cb11b99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "Conv2D(32,kernel_size=(5, 5),activation='sigmoid',input_shape=(28, 28, 1),padding='same')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ff3d988-e5b0-4da9-99b7-227beb004b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = MaxPooling2D(pool_size=(2, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cf28a8-9780-4dd3-912b-8ffa82fb2197",
   "metadata": {},
   "source": [
    "<h3>2.1 Architecture 1 </h3> <br> Couche convolution 2D (nb filtre : 16 ), Pooling, convolution 2D (nb filtre : 32), pooling, applatissement, fonctions d'activation : ReLU (nb de classe : 100), softmax (nb de classe : 10) <br> loss: 230.11% - accuracy: 11.35%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2eed361-4edc-4a80-8ca9-22165b7ccf0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "# Load the dataset\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "# One-hot encoding\n",
    "Y_train = keras.utils.to_categorical(y_train, 10)\n",
    "Y_test = keras.utils.to_categorical(y_test, 10)\n",
    "#  Reshape each 28x28 image -> 784 dim. vector\n",
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "# Normalization\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "nb_classes = 10\n",
    "nb_epoch = 10\n",
    "batch_size = 300\n",
    "model = Sequential()\n",
    "# covolution / pooling alterné \n",
    "# choix de ne pas mettre du pooling\n",
    "model.add(Conv2D(16, kernel_size=(5, 5),  activation='relu',input_shape=input_shape, padding='valid' ))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(32, (5, 5), activation='relu', padding='valid'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# concatene grand vecteur\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(nb_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "learning_rate = 0.5\n",
    "print(\"learning rate=\",learning_rate)\n",
    "optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "\n",
    "#sgd = Adam()\n",
    "model.compile(loss='categorical_crossentropy',optimizer=optimizer,metrics=['accuracy'])\n",
    "\n",
    "#model.fit(X_train, Y_train,batch_size=batch_size, nb_epoch=nb_epoch,verbose=1, validation_data=(X_test, Y_test))\n",
    "model.fit(X_train, Y_train,batch_size=batch_size, epochs=nb_epoch,verbose=1)\n",
    "\n",
    "\n",
    "scores = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[0], scores[0]*100))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b22d754-b5c8-4075-9502-cc45a15d18c2",
   "metadata": {},
   "source": [
    "<h3>2.2 Architecture 2 </h3> <br>Couche convolution 2D (nb filtre : 16 ), Pooling, convolution 2D (nb filtre : 32), pooling, applatissement, fonctions d'activation : ReLU (nb de classe : 128), softmax (nb de classe : 10) <br> loss: 4.82% <br> accuracy: 98.61%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fde4a18-7864-4fd3-b292-bfcee7c1f38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "# Load the dataset\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "# One-hot encoding\n",
    "Y_train = keras.utils.to_categorical(y_train, 10)\n",
    "Y_test = keras.utils.to_categorical(y_test, 10)\n",
    "#  Reshape each 28x28 image -> 784 dim. vector\n",
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "# Normalization\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "nb_classes = 10\n",
    "nb_epoch = 15\n",
    "batch_size = 300\n",
    "model = Sequential()\n",
    "# covolution / pooling alterné \n",
    "# choix de ne pas mettre du pooling\n",
    "model.add(Conv2D(16, kernel_size=(5, 5),  activation='relu',input_shape=input_shape, padding='valid' ))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(32, (5, 5), activation='relu', padding='valid'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# concatene grand vecteur\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(nb_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "learning_rate = 0.5\n",
    "print(\"learning rate=\",learning_rate)\n",
    "optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "\n",
    "#sgd = Adam()\n",
    "model.compile(loss='categorical_crossentropy',optimizer=optimizer,metrics=['accuracy'])\n",
    "\n",
    "#model.fit(X_train, Y_train,batch_size=batch_size, nb_epoch=nb_epoch,verbose=1, validation_data=(X_test, Y_test))\n",
    "model.fit(X_train, Y_train,batch_size=batch_size, epochs=nb_epoch,verbose=1)\n",
    "\n",
    "\n",
    "scores = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[0], scores[0]*100))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
